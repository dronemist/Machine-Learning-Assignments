{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "from cvxopt import solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the SVM data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "svm_train_data = pandas.read_csv('./data/fashion_mnist/train.csv').values\n",
    "svm_test_data = pandas.read_csv('./data/fashion_mnist/test.csv').values\n",
    "svm_validation_data = pandas.read_csv('./data/fashion_mnist/val.csv').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required data\n",
    "svm_train_data_r = svm_train_data[(svm_train_data[:, -1] == (d + 1) % 10) + (svm_train_data[:, -1] == d), :]\n",
    "svm_test_data_r = svm_test_data[(svm_test_data[:, -1] == (d + 1) % 10) + (svm_test_data[:, -1] == d), :]\n",
    "svm_validation_data_r = svm_validation_data[(svm_validation_data[:, -1] == (d + 1) % 10) + (svm_validation_data[:, -1] == d), :]\n",
    "svm_train_data_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading y's\n",
    "y_train = svm_train_data_r[:, -1]\n",
    "y_train[y_train == d] = -1\n",
    "y_train[y_train == (d + 1) % 10] = 1\n",
    "\n",
    "y_test = svm_test_data_r[:, -1]\n",
    "y_test[y_test == d] = -1\n",
    "y_test[y_test == (d + 1) % 10] = 1\n",
    "\n",
    "y_val = svm_validation_data_r[:, -1]\n",
    "y_val[y_val == d] = -1\n",
    "y_val[y_val == (d + 1) % 10] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading x's and normalising\n",
    "x_train = (np.delete(svm_train_data_r, -1, axis = 1) / 255).T\n",
    "x_test = (np.delete(svm_test_data_r, -1, axis = 1) / 255).T\n",
    "x_val = (np.delete(svm_validation_data_r, -1, axis = 1) / 255).T\n",
    "\n",
    "# Noise\n",
    "C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating P matrix\n",
    "def get_p_matrix(x, y, isLinear = True, k_matrix = np.array([])):\n",
    "    y_diag = y.reshape((-1, 1))\n",
    "    if isLinear:\n",
    "        p_matrix = np.matmul(x.T, x)\n",
    "    else:\n",
    "        p_matrix = k_matrix\n",
    "    p_matrix = y_diag * p_matrix\n",
    "    y_diag = y_diag.T\n",
    "    p_matrix = p_matrix * y_diag\n",
    "    p_matrix = matrix(p_matrix)\n",
    "    return p_matrix\n",
    "\n",
    "p_matrix = get_p_matrix(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating q matrix\n",
    "def get_q_matrix(y):\n",
    "    q_matrix = -matrix(np.ones_like(y))\n",
    "    return q_matrix\n",
    "\n",
    "q_matrix = get_q_matrix(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating A and b matrices\n",
    "def get_A_matrix(y):\n",
    "    A_matrix = matrix(y.reshape(1, -1)) \n",
    "    return A_matrix\n",
    "def get_B_matrix():\n",
    "    b_matrix = matrix([0.0])\n",
    "    return b_matrix\n",
    "\n",
    "A_matrix = get_A_matrix(y_train)\n",
    "b_matrix = get_B_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating G and h matrices\n",
    "def get_G_matrix(y):\n",
    "    G_1 = np.identity(np.shape(y)[0])\n",
    "    G_2 = -G_1\n",
    "    G_matrix = matrix(np.vstack((G_1, G_2)))\n",
    "    return G_matrix\n",
    "def get_h_matrix(y):\n",
    "    h_1 = C * np.ones_like(y)\n",
    "    h_2 = 0 * h_1\n",
    "    h_matrix = matrix(np.append(h_1, h_2))\n",
    "    return h_matrix\n",
    "\n",
    "G_matrix = get_G_matrix(y_train)\n",
    "h_matrix = get_h_matrix(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.2396e+02 -9.3983e+03  5e+04  3e+00  3e-12\n",
      " 1: -3.3568e+02 -5.4793e+03  1e+04  5e-01  3e-12\n",
      " 2: -2.0714e+02 -1.8273e+03  3e+03  1e-01  2e-12\n",
      " 3: -1.4999e+02 -9.1602e+02  1e+03  5e-02  1e-12\n",
      " 4: -1.1131e+02 -4.9405e+02  6e+02  2e-02  1e-12\n",
      " 5: -9.0544e+01 -3.1115e+02  3e+02  8e-03  9e-13\n",
      " 6: -8.5666e+01 -1.4689e+02  7e+01  6e-04  1e-12\n",
      " 7: -9.2854e+01 -1.1845e+02  3e+01  2e-14  1e-12\n",
      " 8: -9.8193e+01 -1.0801e+02  1e+01  2e-15  9e-13\n",
      " 9: -1.0058e+02 -1.0337e+02  3e+00  2e-15  1e-12\n",
      "10: -1.0167e+02 -1.0194e+02  3e-01  2e-15  1e-12\n",
      "11: -1.0178e+02 -1.0179e+02  5e-03  4e-15  1e-12\n",
      "12: -1.0179e+02 -1.0179e+02  9e-05  3e-16  1e-12\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# Solving the problem\n",
    "def get_alpha(p, q, G, h, A, b):\n",
    "    sol = solvers.qp(p, q, G, h, A, b)\n",
    "    alpha = np.array(sol['x'])\n",
    "    return alpha\n",
    "\n",
    "alpha = get_alpha(p_matrix, q_matrix, G_matrix, h_matrix, A_matrix, b_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors are: 370\n"
     ]
    }
   ],
   "source": [
    "# Calculating # of Support vectors\n",
    "print(\"Number of support vectors are:\", np.where(alpha > 1e-5)[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating W\n",
    "y_diag = (y_train.reshape((-1, 1))).T\n",
    "w = (x_train * y_diag) @ alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2250)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating b\n",
    "x_temp_0 = svm_train_data[(svm_train_data[:, -1] == d), :]\n",
    "x_temp_0 = (np.delete(x_temp_0, -1, axis = 1) / 255).T\n",
    "x_temp_1 = svm_train_data[(svm_train_data[:, -1] == (d + 1) % 10), :]\n",
    "x_temp_1 = (np.delete(x_temp_1, -1, axis = 1) / 255).T\n",
    "x_temp_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = np.max(w.T @ x_temp_0)\n",
    "minimum = np.min(w.T @ x_temp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = - (maximum + minimum) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 91.3\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test data\n",
    "pred_test = (w.T @ x_test) + b\n",
    "pred_test[pred_test >= 0] = 1\n",
    "pred_test[pred_test < 0] = -1\n",
    "count = 0\n",
    "total = pred_test.shape[1]\n",
    "for (i, p) in enumerate(pred_test[0, :]):\n",
    "    if p == y_test[i]:\n",
    "        count += 1\n",
    "print(\"Accuracy is {}\".format(count * 100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 89.57915831663327\n"
     ]
    }
   ],
   "source": [
    "# Predicting on validation data\n",
    "pred_val = (w.T @ x_val) + b\n",
    "pred_val[pred_val >= 0] = 1\n",
    "pred_val[pred_val < 0] = -1\n",
    "count = 0\n",
    "total = pred_val.shape[1]\n",
    "for (i, p) in enumerate(pred_val[0, :]):\n",
    "    if p == y_val[i]:\n",
    "        count += 1\n",
    "print(\"Accuracy is {}\".format(count * 100 / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, cdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Gaussian Kernel\n",
    "def get_k_matrix(x0, x1):\n",
    "    return np.exp(-gamma * cdist(x0.T, x1.T) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Gaussian\n",
    "gamma = 0.05\n",
    "# pairwise_dists = squareform(pdist(x_train.T, 'euclidean'))\n",
    "k_matrix = get_k_matrix(x_train, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing P_matrix\n",
    "p_matrix = get_p_matrix(x_train, y_train, False, k_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0404e+02 -8.2833e+03  4e+04  2e+00  2e-15\n",
      " 1: -2.1981e+02 -4.4663e+03  7e+03  3e-01  2e-15\n",
      " 2: -1.8274e+02 -1.0106e+03  1e+03  3e-02  4e-15\n",
      " 3: -2.3561e+02 -4.7608e+02  3e+02  6e-03  2e-15\n",
      " 4: -2.6244e+02 -3.3488e+02  8e+01  1e-03  2e-15\n",
      " 5: -2.7389e+02 -2.9769e+02  2e+01  2e-04  2e-15\n",
      " 6: -2.7877e+02 -2.8539e+02  7e+00  4e-05  2e-15\n",
      " 7: -2.8041e+02 -2.8192e+02  2e+00  3e-06  2e-15\n",
      " 8: -2.8091e+02 -2.8102e+02  1e-01  7e-08  2e-15\n",
      " 9: -2.8095e+02 -2.8095e+02  2e-03  9e-10  2e-15\n",
      "10: -2.8095e+02 -2.8095e+02  4e-05  1e-11  2e-15\n",
      "Optimal solution found.\n",
      "Training time (test): 17.474s\n"
     ]
    }
   ],
   "source": [
    "# Solving the problem\n",
    "t0 = time()\n",
    "alpha = get_alpha(p_matrix, q_matrix, G_matrix, h_matrix, A_matrix, b_matrix)\n",
    "print(f\"Training time (test): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors are:  1123\n"
     ]
    }
   ],
   "source": [
    "# Calculating alpha\n",
    "print(\"Number of support vectors are: \", np.where(alpha > 1e-5)[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating B\n",
    "def get_gauss_b(x0, x1, x, y, a):\n",
    "    x_list_0 = np.sum(y[:, None] * a * get_k_matrix(x, x0), axis = 0)\n",
    "    x_list_1 = np.sum(y[:, None] * a * get_k_matrix(x, x1), axis = 0)\n",
    "    b = -(np.max(x_list_0) + np.min(x_list_1)) / 2.0\n",
    "    return b\n",
    "\n",
    "# Extracting the xi's\n",
    "x_temp_0 = svm_train_data[(svm_train_data[:, -1] == d), :]\n",
    "x_temp_0 = (np.delete(x_temp_0, -1, axis = 1) / 255).T\n",
    "x_temp_1 = svm_train_data[(svm_train_data[:, -1] == (d + 1) % 10), :]\n",
    "x_temp_1 = (np.delete(x_temp_1, -1, axis = 1) / 255).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (test): 15.888s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "b = get_gauss_b(x_temp_0, x_temp_1, x_train, y_train, alpha)\n",
    "print(f\"Training time (test): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gauss_prediction(a, b, x, y, x_t):\n",
    "    k_matrix_test = y[:, None] * a * get_k_matrix(x, x_t)\n",
    "    return np.sum(k_matrix_test, axis = 0) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is 96.1\n",
      "Prediction time (test): 3.353s\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test data\n",
    "t0 = time()\n",
    "pred_test = get_gauss_prediction(alpha, b, x_train, y_train, x_test)\n",
    "pred_test[pred_test >= 0] = 1\n",
    "pred_test[pred_test < 0] = -1\n",
    "count = 0\n",
    "total = pred_test.shape[0]\n",
    "for (i, p) in enumerate(pred_test):\n",
    "    if p == y_test[i]:\n",
    "        count += 1\n",
    "print(\"Test Accuracy is {}\".format(count * 100 / total))\n",
    "print(f\"Prediction time (test): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy is 97.1943887775551\n",
      "Prediction time (Validation): 1.727s\n"
     ]
    }
   ],
   "source": [
    "# Predicting on validation data\n",
    "t0 = time()\n",
    "pred_val = get_gauss_prediction(alpha, b, x_train, y_train, x_val)\n",
    "pred_val[pred_val >= 0] = 1\n",
    "pred_val[pred_val < 0] = -1\n",
    "count = 0\n",
    "total = pred_val.shape[0]\n",
    "for (i, p) in enumerate(pred_val):\n",
    "    if p == y_val[i]:\n",
    "        count += 1\n",
    "print(\"Validation Accuracy is {}\".format(count * 100 / total))\n",
    "print(f\"Prediction time (Validation): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Accuracy(test): 0.957\n",
      "Linear Accuracy(validation): 0.969939879759519\n",
      "Number of support vectors: 363\n"
     ]
    }
   ],
   "source": [
    "# Linear \n",
    "# Create a svm Classifier\n",
    "clf = SVC(kernel='linear', C=C) # Linear Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(x_train.T, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Linear Accuracy(test):\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Predict the response for validation dataset\n",
    "y_pred = clf.predict(x_val.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Linear Accuracy(validation):\", metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Number of support vectors:\", np.sum(clf.n_support_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Accuracy(test): 0.972\n",
      "Gaussian Accuracy(validation): 0.9819639278557114\n",
      "Number of support vectors: 1102\n"
     ]
    }
   ],
   "source": [
    "# Gaussian\n",
    "# Create a svm Classifier\n",
    "clf = SVC(kernel='rbf', gamma=gamma, C=C) # Gaussian Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(x_train.T, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Gaussian Accuracy(test):\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Predict the response for validation dataset\n",
    "y_pred = clf.predict(x_val.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Gaussian Accuracy(validation):\", metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Number of support vectors:\", np.sum(clf.n_support_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading training data\n",
    "X_train = {}\n",
    "Y_train = {}\n",
    "y_train_m = svm_train_data[:, -1]\n",
    "x_train_m = (np.delete(svm_train_data, -1, axis = 1) / 255).T\n",
    "for i in range(10):\n",
    "    svm_train_data_t = svm_train_data[(svm_train_data[:, -1] == i), :]\n",
    "    Y_train[i] = svm_train_data_t[:, -1]\n",
    "    X_train[i] = (np.delete(svm_train_data_t, -1, axis = 1) / 255).T\n",
    "\n",
    "# Reading test data\n",
    "X_test = {}\n",
    "Y_test = {}\n",
    "temp = np.copy(svm_test_data)\n",
    "x_test_m = (np.delete(temp, -1, axis = 1) / 255).T\n",
    "y_test_m = temp[:, -1]\n",
    "for i in range(10):\n",
    "    svm_test_data_t = svm_test_data[(svm_test_data[:, -1] == i), :]\n",
    "    Y_test[i] = svm_test_data_t[:, -1]\n",
    "    X_test[i] = (np.delete(svm_test_data_t, -1, axis = 1) / 255).T\n",
    "\n",
    "# Reading validation data\n",
    "X_val = {}\n",
    "Y_val = {}\n",
    "temp = np.copy(svm_validation_data)\n",
    "x_validation = (np.delete(temp, -1, axis = 1) / 255).T\n",
    "y_validation = temp[:, -1]\n",
    "for i in range(10):\n",
    "    svm_val_data_t = svm_validation_data[(svm_validation_data[:, -1] == i), :]\n",
    "    Y_val[i] = svm_val_data_t[:, -1]\n",
    "    X_val[i] = (np.delete(svm_val_data_t, -1, axis = 1) / 255).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating alpha's matrices\n",
    "def get_alpha_s(X, Y):\n",
    "    alpha_d = {}\n",
    "    for i in range(10):\n",
    "        for j in range(i + 1, 10):\n",
    "            # Getting alpha for i vs j classification\n",
    "            x = np.vstack((X[i].T, X[j].T)).T\n",
    "            y = np.append(Y[i], Y[j])\n",
    "            y[y == i] = -1\n",
    "            y[y == j % 10] = 1\n",
    "            \n",
    "            # Calculating the relevant matrices\n",
    "            k = get_k_matrix(x, x)\n",
    "            p = get_p_matrix(x, y, isLinear=False, k_matrix = k)\n",
    "            q = get_q_matrix(y)\n",
    "            G = get_G_matrix(y)\n",
    "            h = get_h_matrix(y)\n",
    "            A = get_A_matrix(y)\n",
    "            B_matrix = get_B_matrix()\n",
    "\n",
    "            alpha_d[i, j] = get_alpha(p, q, G, h, A, B_matrix)\n",
    "    return alpha_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b_dict(X, Y, alpha_dict):\n",
    "    b_dict = {}\n",
    "    for i in range(10):\n",
    "        for j in range(i + 1, 10):\n",
    "            \n",
    "            print(i, j)\n",
    "            \n",
    "            # Getting b for i vs j classification\n",
    "            x = np.vstack((X[i].T, X[j].T)).T\n",
    "            y = np.append(Y[i], Y[j])\n",
    "            y[y == i] = -1\n",
    "            y[y == j % 10] = 1\n",
    "\n",
    "            # Calculating the relevant matrices\n",
    "            b_dict[i, j] = get_gauss_b(X[i], X[j] , x, y, alpha_dict[i, j])\n",
    "            \n",
    "    return b_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6492e+02 -6.6070e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.1407e+02 -3.0686e+03  5e+03  2e-01  4e-15\n",
      " 2: -1.0459e+02 -7.6952e+02  9e+02  3e-02  5e-15\n",
      " 3: -1.2684e+02 -3.0203e+02  2e+02  6e-03  4e-15\n",
      " 4: -1.4133e+02 -2.0101e+02  6e+01  1e-03  3e-15\n",
      " 5: -1.4945e+02 -1.6809e+02  2e+01  2e-04  3e-15\n",
      " 6: -1.5144e+02 -1.6280e+02  1e+01  3e-05  3e-15\n",
      " 7: -1.5364e+02 -1.5728e+02  4e+00  7e-06  3e-15\n",
      " 8: -1.5443e+02 -1.5550e+02  1e+00  6e-14  3e-15\n",
      " 9: -1.5478e+02 -1.5492e+02  1e-01  7e-14  3e-15\n",
      "10: -1.5483e+02 -1.5484e+02  4e-03  1e-14  3e-15\n",
      "11: -1.5483e+02 -1.5483e+02  6e-05  7e-14  3e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7366e+02 -8.4330e+03  4e+04  2e+00  6e-15\n",
      " 1: -2.8341e+02 -4.5691e+03  7e+03  2e-01  5e-15\n",
      " 2: -2.6181e+02 -1.1549e+03  1e+03  3e-02  6e-15\n",
      " 3: -3.1375e+02 -5.8168e+02  3e+02  6e-03  5e-15\n",
      " 4: -3.4227e+02 -4.1865e+02  8e+01  1e-03  5e-15\n",
      " 5: -3.5409e+02 -3.7849e+02  2e+01  2e-04  5e-15\n",
      " 6: -3.5907e+02 -3.6537e+02  6e+00  2e-05  5e-15\n",
      " 7: -3.6070e+02 -3.6180e+02  1e+00  2e-06  5e-15\n",
      " 8: -3.6105e+02 -3.6113e+02  8e-02  1e-07  5e-15\n",
      " 9: -3.6108e+02 -3.6108e+02  2e-03  3e-09  5e-15\n",
      "10: -3.6108e+02 -3.6108e+02  4e-05  4e-11  5e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.0649e+02 -8.5038e+03  4e+04  2e+00  9e-15\n",
      " 1: -4.0102e+02 -4.7685e+03  7e+03  2e-01  9e-15\n",
      " 2: -3.8628e+02 -1.1830e+03  9e+02  2e-02  1e-14\n",
      " 3: -4.5117e+02 -7.2740e+02  3e+02  6e-03  9e-15\n",
      " 4: -4.8441e+02 -5.8062e+02  1e+02  1e-03  9e-15\n",
      " 5: -5.0013e+02 -5.2734e+02  3e+01  2e-05  1e-14\n",
      " 6: -5.0580e+02 -5.1293e+02  7e+00  1e-06  1e-14\n",
      " 7: -5.0772e+02 -5.0866e+02  9e-01  5e-13  1e-14\n",
      " 8: -5.0800e+02 -5.0814e+02  1e-01  1e-12  1e-14\n",
      " 9: -5.0805e+02 -5.0806e+02  6e-03  1e-12  1e-14\n",
      "10: -5.0805e+02 -5.0805e+02  2e-04  2e-13  1e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6859e+02 -7.0722e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.9279e+02 -3.5589e+03  5e+03  2e-01  4e-15\n",
      " 2: -1.7237e+02 -8.6876e+02  9e+02  3e-02  5e-15\n",
      " 3: -2.1276e+02 -4.3671e+02  3e+02  7e-03  4e-15\n",
      " 4: -2.3708e+02 -3.0397e+02  7e+01  1e-03  4e-15\n",
      " 5: -2.4834e+02 -2.6677e+02  2e+01  3e-04  4e-15\n",
      " 6: -2.5227e+02 -2.5748e+02  5e+00  6e-05  3e-15\n",
      " 7: -2.5364e+02 -2.5461e+02  1e+00  3e-13  4e-15\n",
      " 8: -2.5398e+02 -2.5404e+02  5e-02  2e-13  4e-15\n",
      " 9: -2.5400e+02 -2.5401e+02  1e-03  6e-14  4e-15\n",
      "10: -2.5400e+02 -2.5400e+02  3e-05  1e-13  4e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9695e+02 -7.3586e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.3156e+02 -3.7924e+03  6e+03  2e-01  3e-15\n",
      " 2: -1.0044e+02 -9.5862e+02  1e+03  4e-02  5e-15\n",
      " 3: -1.3520e+02 -3.4385e+02  2e+02  7e-03  3e-15\n",
      " 4: -1.5380e+02 -2.1468e+02  6e+01  8e-04  2e-15\n",
      " 5: -1.6313e+02 -1.8372e+02  2e+01  4e-14  2e-15\n",
      " 6: -1.6684e+02 -1.7390e+02  7e+00  6e-14  2e-15\n",
      " 7: -1.6824e+02 -1.7054e+02  2e+00  1e-13  2e-15\n",
      " 8: -1.6888e+02 -1.6928e+02  4e-01  1e-13  2e-15\n",
      " 9: -1.6902e+02 -1.6903e+02  2e-02  3e-13  2e-15\n",
      "10: -1.6902e+02 -1.6902e+02  3e-04  1e-13  2e-15\n",
      "11: -1.6902e+02 -1.6902e+02  4e-06  1e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0396e+03 -9.5846e+03  4e+04  2e+00  1e-14\n",
      " 1: -8.6974e+02 -5.8661e+03  7e+03  2e-01  2e-14\n",
      " 2: -8.9358e+02 -1.8092e+03  1e+03  2e-02  2e-14\n",
      " 3: -9.9727e+02 -1.2864e+03  3e+02  5e-03  2e-14\n",
      " 4: -1.0441e+03 -1.1319e+03  9e+01  8e-04  2e-14\n",
      " 5: -1.0607e+03 -1.0851e+03  2e+01  2e-04  2e-14\n",
      " 6: -1.0662e+03 -1.0717e+03  6e+00  3e-05  2e-14\n",
      " 7: -1.0675e+03 -1.0687e+03  1e+00  4e-06  2e-14\n",
      " 8: -1.0679e+03 -1.0679e+03  5e-02  3e-08  2e-14\n",
      " 9: -1.0679e+03 -1.0679e+03  1e-03  6e-10  2e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0789e+02 -7.4144e+03  4e+04  2e+00  5e-15\n",
      " 1: -5.8581e+01 -3.7245e+03  6e+03  3e-01  3e-15\n",
      " 2: -1.8417e+01 -8.7407e+02  1e+03  4e-02  7e-15\n",
      " 3: -3.8829e+01 -1.9635e+02  2e+02  5e-03  4e-15\n",
      " 4: -5.5771e+01 -1.0639e+02  5e+01  1e-03  3e-15\n",
      " 5: -6.3792e+01 -8.0947e+01  2e+01  1e-04  2e-15\n",
      " 6: -6.7399e+01 -7.2673e+01  5e+00  2e-05  2e-15\n",
      " 7: -6.8657e+01 -7.0232e+01  2e+00  1e-06  2e-15\n",
      " 8: -6.9169e+01 -6.9365e+01  2e-01  9e-09  2e-15\n",
      " 9: -6.9247e+01 -6.9257e+01  1e-02  4e-10  2e-15\n",
      "10: -6.9251e+01 -6.9251e+01  2e-04  6e-12  2e-15\n",
      "11: -6.9251e+01 -6.9251e+01  3e-06  9e-14  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7984e+02 -7.6220e+03  3e+04  2e+00  5e-15\n",
      " 1: -2.0299e+02 -4.0371e+03  6e+03  2e-01  3e-15\n",
      " 2: -1.7493e+02 -1.2336e+03  1e+03  4e-02  4e-15\n",
      " 3: -2.1659e+02 -4.2387e+02  2e+02  6e-03  3e-15\n",
      " 4: -2.4162e+02 -2.9524e+02  6e+01  7e-04  2e-15\n",
      " 5: -2.5192e+02 -2.6612e+02  1e+01  1e-04  2e-15\n",
      " 6: -2.5529e+02 -2.5891e+02  4e+00  2e-05  2e-15\n",
      " 7: -2.5634e+02 -2.5681e+02  5e-01  8e-07  2e-15\n",
      " 8: -2.5650e+02 -2.5653e+02  3e-02  4e-08  2e-15\n",
      " 9: -2.5651e+02 -2.5651e+02  6e-04  7e-10  2e-15\n",
      "10: -2.5651e+02 -2.5651e+02  1e-05  1e-11  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3464e+02 -6.8388e+03  3e+04  2e+00  5e-15\n",
      " 1: -7.6690e+01 -3.2910e+03  5e+03  2e-01  2e-15\n",
      " 2: -5.4390e+01 -6.8811e+02  8e+02  3e-02  4e-15\n",
      " 3: -8.6653e+01 -2.4599e+02  2e+02  5e-03  3e-15\n",
      " 4: -1.0255e+02 -1.5246e+02  5e+01  1e-03  2e-15\n",
      " 5: -1.0963e+02 -1.2739e+02  2e+01  3e-04  2e-15\n",
      " 6: -1.1318e+02 -1.1820e+02  5e+00  4e-05  2e-15\n",
      " 7: -1.1445e+02 -1.1556e+02  1e+00  4e-06  2e-15\n",
      " 8: -1.1479e+02 -1.1496e+02  2e-01  5e-07  2e-15\n",
      " 9: -1.1485e+02 -1.1486e+02  5e-03  9e-09  2e-15\n",
      "10: -1.1485e+02 -1.1485e+02  1e-04  2e-10  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3552e+02 -7.1330e+03  3e+04  2e+00  5e-15\n",
      " 1: -8.6508e+01 -3.3924e+03  5e+03  2e-01  3e-15\n",
      " 2: -7.2456e+01 -7.5584e+02  9e+02  3e-02  3e-15\n",
      " 3: -9.8211e+01 -2.9087e+02  2e+02  6e-03  3e-15\n",
      " 4: -1.1260e+02 -1.7965e+02  7e+01  2e-03  2e-15\n",
      " 5: -1.2011e+02 -1.4295e+02  2e+01  3e-04  2e-15\n",
      " 6: -1.2381e+02 -1.3099e+02  7e+00  6e-14  2e-15\n",
      " 7: -1.2520e+02 -1.2765e+02  2e+00  7e-14  2e-15\n",
      " 8: -1.2579e+02 -1.2645e+02  7e-01  6e-14  2e-15\n",
      " 9: -1.2601e+02 -1.2606e+02  5e-02  2e-16  2e-15\n",
      "10: -1.2603e+02 -1.2603e+02  1e-03  6e-14  2e-15\n",
      "11: -1.2603e+02 -1.2603e+02  1e-05  1e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2920e+02 -7.6513e+03  4e+04  2e+00  6e-15\n",
      " 1: -1.5609e+02 -3.9103e+03  6e+03  2e-01  6e-15\n",
      " 2: -1.3600e+02 -9.2629e+02  1e+03  3e-02  7e-15\n",
      " 3: -1.7295e+02 -4.3323e+02  3e+02  7e-03  6e-15\n",
      " 4: -1.9647e+02 -2.7544e+02  8e+01  1e-03  5e-15\n",
      " 5: -2.0746e+02 -2.3515e+02  3e+01  1e-04  5e-15\n",
      " 6: -2.1226e+02 -2.2191e+02  1e+01  2e-05  5e-15\n",
      " 7: -2.1376e+02 -2.1815e+02  4e+00  2e-13  6e-15\n",
      " 8: -2.1495e+02 -2.1581e+02  9e-01  7e-13  5e-15\n",
      " 9: -2.1517e+02 -2.1539e+02  2e-01  8e-13  5e-15\n",
      "10: -2.1525e+02 -2.1526e+02  7e-03  3e-13  6e-15\n",
      "11: -2.1526e+02 -2.1526e+02  1e-04  3e-13  6e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2784e+02 -6.4239e+03  3e+04  2e+00  5e-15\n",
      " 1: -8.0058e+01 -2.9152e+03  4e+03  2e-01  3e-15\n",
      " 2: -6.9558e+01 -6.4681e+02  7e+02  3e-02  3e-15\n",
      " 3: -9.4376e+01 -2.5073e+02  2e+02  5e-03  3e-15\n",
      " 4: -1.0877e+02 -1.5571e+02  5e+01  7e-04  2e-15\n",
      " 5: -1.1554e+02 -1.3286e+02  2e+01  1e-04  2e-15\n",
      " 6: -1.1887e+02 -1.2384e+02  5e+00  2e-06  2e-15\n",
      " 7: -1.2010e+02 -1.2121e+02  1e+00  5e-14  2e-15\n",
      " 8: -1.2044e+02 -1.2063e+02  2e-01  1e-13  2e-15\n",
      " 9: -1.2051e+02 -1.2052e+02  1e-02  1e-13  2e-15\n",
      "10: -1.2052e+02 -1.2052e+02  2e-04  4e-14  2e-15\n",
      "11: -1.2052e+02 -1.2052e+02  9e-06  2e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.3951e+01 -6.5170e+03  3e+04  2e+00  5e-15\n",
      " 1: -5.0071e+01 -2.9486e+03  5e+03  2e-01  2e-15\n",
      " 2: -3.9044e+01 -6.7804e+02  8e+02  3e-02  4e-15\n",
      " 3: -6.0171e+01 -2.0555e+02  2e+02  5e-03  3e-15\n",
      " 4: -7.2612e+01 -1.1948e+02  5e+01  1e-03  2e-15\n",
      " 5: -7.7571e+01 -9.6384e+01  2e+01  1e-04  2e-15\n",
      " 6: -7.9823e+01 -8.8987e+01  9e+00  2e-13  2e-15\n",
      " 7: -8.1320e+01 -8.4534e+01  3e+00  6e-14  1e-15\n",
      " 8: -8.1920e+01 -8.3011e+01  1e+00  8e-14  1e-15\n",
      " 9: -8.2190e+01 -8.2481e+01  3e-01  1e-14  1e-15\n",
      "10: -8.2277e+01 -8.2328e+01  5e-02  9e-14  1e-15\n",
      "11: -8.2296e+01 -8.2298e+01  2e-03  1e-13  1e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12: -8.2297e+01 -8.2297e+01  4e-05  2e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6321e+02 -6.5609e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.1075e+02 -3.0589e+03  5e+03  2e-01  3e-15\n",
      " 2: -1.0167e+02 -7.6887e+02  9e+02  3e-02  4e-15\n",
      " 3: -1.2535e+02 -3.1952e+02  2e+02  7e-03  3e-15\n",
      " 4: -1.4028e+02 -2.0638e+02  7e+01  2e-03  3e-15\n",
      " 5: -1.4794e+02 -1.7118e+02  2e+01  2e-04  3e-15\n",
      " 6: -1.5107e+02 -1.6136e+02  1e+01  1e-05  3e-15\n",
      " 7: -1.5295e+02 -1.5632e+02  3e+00  3e-06  2e-15\n",
      " 8: -1.5376e+02 -1.5442e+02  7e-01  1e-13  3e-15\n",
      " 9: -1.5397e+02 -1.5405e+02  8e-02  2e-13  3e-15\n",
      "10: -1.5400e+02 -1.5400e+02  2e-03  2e-13  3e-15\n",
      "11: -1.5400e+02 -1.5400e+02  6e-05  4e-14  3e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.5955e+01 -6.5221e+03  3e+04  2e+00  5e-15\n",
      " 1: -3.1834e+01 -2.9574e+03  5e+03  2e-01  2e-15\n",
      " 2: -1.0088e+01 -5.1383e+02  7e+02  2e-02  5e-15\n",
      " 3: -2.7978e+01 -1.2024e+02  1e+02  3e-03  3e-15\n",
      " 4: -3.8190e+01 -7.0454e+01  3e+01  8e-04  2e-15\n",
      " 5: -4.2441e+01 -5.6406e+01  1e+01  3e-04  2e-15\n",
      " 6: -4.4726e+01 -5.0658e+01  6e+00  5e-05  1e-15\n",
      " 7: -4.5554e+01 -4.8795e+01  3e+00  1e-13  1e-15\n",
      " 8: -4.6276e+01 -4.7407e+01  1e+00  3e-14  1e-15\n",
      " 9: -4.6545e+01 -4.6900e+01  4e-01  1e-14  2e-15\n",
      "10: -4.6685e+01 -4.6706e+01  2e-02  4e-14  2e-15\n",
      "11: -4.6694e+01 -4.6695e+01  4e-04  9e-14  2e-15\n",
      "12: -4.6694e+01 -4.6694e+01  5e-06  8e-14  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1469e+02 -6.6612e+03  3e+04  2e+00  5e-15\n",
      " 1: -6.4473e+01 -3.0959e+03  5e+03  2e-01  2e-15\n",
      " 2: -5.1691e+01 -7.9899e+02  1e+03  3e-02  3e-15\n",
      " 3: -7.6800e+01 -2.6329e+02  2e+02  6e-03  3e-15\n",
      " 4: -9.2410e+01 -1.4435e+02  5e+01  1e-03  2e-15\n",
      " 5: -9.8364e+01 -1.1956e+02  2e+01  3e-04  2e-15\n",
      " 6: -1.0088e+02 -1.1105e+02  1e+01  9e-14  2e-15\n",
      " 7: -1.0257e+02 -1.0606e+02  3e+00  2e-13  1e-15\n",
      " 8: -1.0324e+02 -1.0426e+02  1e+00  1e-13  2e-15\n",
      " 9: -1.0355e+02 -1.0367e+02  1e-01  3e-14  2e-15\n",
      "10: -1.0359e+02 -1.0359e+02  5e-03  3e-14  2e-15\n",
      "11: -1.0359e+02 -1.0359e+02  1e-04  1e-13  2e-15\n",
      "12: -1.0359e+02 -1.0359e+02  2e-06  9e-14  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.7086e+01 -6.2810e+03  3e+04  2e+00  4e-15\n",
      " 1: -3.6190e+01 -2.7260e+03  4e+03  2e-01  2e-15\n",
      " 2: -2.6916e+01 -5.5124e+02  7e+02  2e-02  3e-15\n",
      " 3: -4.8738e+01 -1.5892e+02  1e+02  3e-03  3e-15\n",
      " 4: -5.9871e+01 -9.4267e+01  4e+01  8e-04  2e-15\n",
      " 5: -6.4611e+01 -7.7166e+01  1e+01  1e-04  2e-15\n",
      " 6: -6.6205e+01 -7.3281e+01  7e+00  8e-06  1e-15\n",
      " 7: -6.7614e+01 -6.9700e+01  2e+00  2e-06  1e-15\n",
      " 8: -6.8024e+01 -6.8779e+01  8e-01  1e-13  1e-15\n",
      " 9: -6.8259e+01 -6.8394e+01  1e-01  6e-14  1e-15\n",
      "10: -6.8310e+01 -6.8315e+01  5e-03  9e-14  1e-15\n",
      "11: -6.8312e+01 -6.8312e+01  1e-04  7e-15  1e-15\n",
      "12: -6.8312e+01 -6.8312e+01  2e-06  6e-14  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0404e+02 -8.2833e+03  4e+04  2e+00  6e-15\n",
      " 1: -2.1981e+02 -4.4663e+03  7e+03  3e-01  4e-15\n",
      " 2: -1.8274e+02 -1.0106e+03  1e+03  3e-02  6e-15\n",
      " 3: -2.3561e+02 -4.7608e+02  3e+02  6e-03  4e-15\n",
      " 4: -2.6244e+02 -3.3488e+02  8e+01  1e-03  4e-15\n",
      " 5: -2.7389e+02 -2.9769e+02  2e+01  2e-04  4e-15\n",
      " 6: -2.7877e+02 -2.8539e+02  7e+00  4e-05  4e-15\n",
      " 7: -2.8041e+02 -2.8192e+02  2e+00  3e-06  4e-15\n",
      " 8: -2.8091e+02 -2.8102e+02  1e-01  7e-08  4e-15\n",
      " 9: -2.8095e+02 -2.8095e+02  2e-03  9e-10  4e-15\n",
      "10: -2.8095e+02 -2.8095e+02  4e-05  1e-11  4e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.4630e+02 -1.0583e+04  5e+04  3e+00  1e-14\n",
      " 1: -7.4464e+02 -6.9192e+03  9e+03  3e-01  2e-14\n",
      " 2: -7.6719e+02 -1.7237e+03  1e+03  2e-02  2e-14\n",
      " 3: -8.9919e+02 -1.2167e+03  3e+02  4e-03  2e-14\n",
      " 4: -9.4723e+02 -1.0952e+03  1e+02  1e-03  2e-14\n",
      " 5: -9.7572e+02 -1.0167e+03  4e+01  2e-04  2e-14\n",
      " 6: -9.8536e+02 -9.9280e+02  7e+00  1e-05  2e-14\n",
      " 7: -9.8745e+02 -9.8827e+02  8e-01  1e-07  2e-14\n",
      " 8: -9.8772e+02 -9.8774e+02  3e-02  3e-09  2e-14\n",
      " 9: -9.8773e+02 -9.8773e+02  5e-04  5e-11  2e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8702e+02 -7.3983e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.1528e+02 -3.8475e+03  6e+03  2e-01  3e-15\n",
      " 2: -8.4085e+01 -8.9251e+02  1e+03  3e-02  6e-15\n",
      " 3: -1.3534e+02 -2.8791e+02  2e+02  4e-03  3e-15\n",
      " 4: -1.5510e+02 -2.0703e+02  5e+01  7e-04  2e-15\n",
      " 5: -1.6372e+02 -1.8109e+02  2e+01  8e-05  2e-15\n",
      " 6: -1.6706e+02 -1.7274e+02  6e+00  2e-06  2e-15\n",
      " 7: -1.6834e+02 -1.6982e+02  1e+00  1e-14  2e-15\n",
      " 8: -1.6876e+02 -1.6898e+02  2e-01  6e-13  2e-15\n",
      " 9: -1.6884e+02 -1.6885e+02  7e-03  5e-13  2e-15\n",
      "10: -1.6884e+02 -1.6884e+02  1e-04  3e-14  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.6781e+02 -1.0280e+04  5e+04  3e+00  1e-14\n",
      " 1: -7.7941e+02 -6.5268e+03  8e+03  2e-01  2e-14\n",
      " 2: -8.3083e+02 -1.8673e+03  1e+03  2e-02  2e-14\n",
      " 3: -9.4685e+02 -1.2637e+03  3e+02  5e-03  2e-14\n",
      " 4: -9.9989e+02 -1.0807e+03  8e+01  7e-04  2e-14\n",
      " 5: -1.0159e+03 -1.0374e+03  2e+01  1e-04  2e-14\n",
      " 6: -1.0214e+03 -1.0238e+03  2e+00  8e-06  2e-14\n",
      " 7: -1.0221e+03 -1.0223e+03  2e-01  6e-07  2e-14\n",
      " 8: -1.0222e+03 -1.0222e+03  7e-03  1e-08  2e-14\n",
      " 9: -1.0222e+03 -1.0222e+03  2e-04  2e-10  2e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0352e+02 -7.4392e+03  4e+04  2e+00  5e-15\n",
      " 1: -5.2259e+01 -3.7516e+03  6e+03  3e-01  3e-15\n",
      " 2: -1.0077e+01 -8.8825e+02  1e+03  4e-02  8e-15\n",
      " 3: -3.5635e+01 -1.9440e+02  2e+02  5e-03  4e-15\n",
      " 4: -5.4188e+01 -1.0235e+02  5e+01  9e-04  3e-15\n",
      " 5: -6.2019e+01 -7.9857e+01  2e+01  1e-04  2e-15\n",
      " 6: -6.5729e+01 -7.1122e+01  5e+00  5e-06  2e-15\n",
      " 7: -6.7167e+01 -6.8294e+01  1e+00  3e-07  2e-15\n",
      " 8: -6.7544e+01 -6.7677e+01  1e-01  2e-08  2e-15\n",
      " 9: -6.7596e+01 -6.7602e+01  6e-03  6e-14  2e-15\n",
      "10: -6.7599e+01 -6.7599e+01  9e-05  7e-15  2e-15\n",
      "11: -6.7599e+01 -6.7599e+01  3e-06  1e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7490e+02 -7.4241e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.9123e+02 -3.9068e+03  6e+03  2e-01  3e-15\n",
      " 2: -1.6914e+02 -1.0114e+03  1e+03  3e-02  4e-15\n",
      " 3: -2.2772e+02 -4.2201e+02  2e+02  5e-03  3e-15\n",
      " 4: -2.5292e+02 -3.0412e+02  5e+01  8e-04  2e-15\n",
      " 5: -2.6267e+02 -2.7651e+02  1e+01  1e-04  2e-15\n",
      " 6: -2.6583e+02 -2.6927e+02  3e+00  2e-05  2e-15\n",
      " 7: -2.6678e+02 -2.6733e+02  6e-01  3e-06  2e-15\n",
      " 8: -2.6696e+02 -2.6699e+02  3e-02  1e-07  2e-15\n",
      " 9: -2.6697e+02 -2.6697e+02  6e-04  2e-09  2e-15\n",
      "10: -2.6697e+02 -2.6697e+02  1e-05  2e-11  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3122e+02 -6.8313e+03  3e+04  2e+00  5e-15\n",
      " 1: -6.8632e+01 -3.3021e+03  5e+03  2e-01  2e-15\n",
      " 2: -4.4226e+01 -5.7527e+02  6e+02  2e-02  5e-15\n",
      " 3: -8.9948e+01 -1.9526e+02  1e+02  2e-03  3e-15\n",
      " 4: -1.0529e+02 -1.3890e+02  3e+01  6e-04  2e-15\n",
      " 5: -1.1181e+02 -1.2245e+02  1e+01  1e-04  2e-15\n",
      " 6: -1.1461e+02 -1.1691e+02  2e+00  8e-06  2e-15\n",
      " 7: -1.1534e+02 -1.1566e+02  3e-01  3e-07  2e-15\n",
      " 8: -1.1546e+02 -1.1548e+02  2e-02  4e-09  2e-15\n",
      " 9: -1.1546e+02 -1.1547e+02  5e-04  1e-10  2e-15\n",
      "10: -1.1546e+02 -1.1546e+02  1e-05  2e-12  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2846e+02 -7.6683e+03  3e+04  2e+00  7e-15\n",
      " 1: -3.2882e+02 -4.1247e+03  6e+03  2e-01  6e-15\n",
      " 2: -3.0989e+02 -9.4797e+02  7e+02  2e-02  7e-15\n",
      " 3: -3.7592e+02 -5.6057e+02  2e+02  4e-03  6e-15\n",
      " 4: -4.0510e+02 -4.5864e+02  6e+01  7e-04  6e-15\n",
      " 5: -4.1586e+02 -4.3199e+02  2e+01  1e-04  7e-15\n",
      " 6: -4.1976e+02 -4.2383e+02  4e+00  1e-05  7e-15\n",
      " 7: -4.2092e+02 -4.2164e+02  7e-01  1e-13  7e-15\n",
      " 8: -4.2117e+02 -4.2123e+02  6e-02  3e-13  7e-15\n",
      " 9: -4.2119e+02 -4.2119e+02  1e-03  5e-13  7e-15\n",
      "10: -4.2119e+02 -4.2119e+02  2e-05  2e-13  7e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5807e+02 -7.8935e+03  4e+04  2e+00  4e-15\n",
      " 1: -8.8653e+01 -4.1540e+03  7e+03  3e-01  2e-15\n",
      " 2: -4.1510e+01 -1.0103e+03  1e+03  4e-02  5e-15\n",
      " 3: -8.5734e+01 -2.6570e+02  2e+02  5e-03  3e-15\n",
      " 4: -1.0518e+02 -1.7624e+02  8e+01  2e-03  2e-15\n",
      " 5: -1.1476e+02 -1.4038e+02  3e+01  3e-04  2e-15\n",
      " 6: -1.1877e+02 -1.2915e+02  1e+01  1e-14  2e-15\n",
      " 7: -1.2051e+02 -1.2483e+02  4e+00  1e-14  2e-15\n",
      " 8: -1.2142e+02 -1.2269e+02  1e+00  7e-14  2e-15\n",
      " 9: -1.2181e+02 -1.2194e+02  1e-01  2e-13  2e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: -1.2186e+02 -1.2187e+02  1e-02  6e-14  2e-15\n",
      "11: -1.2186e+02 -1.2186e+02  1e-04  1e-13  2e-15\n",
      "12: -1.2186e+02 -1.2186e+02  3e-06  2e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.1433e+02 -9.6131e+03  5e+04  3e+00  8e-15\n",
      " 1: -3.9419e+02 -5.7409e+03  8e+03  3e-01  8e-15\n",
      " 2: -3.6455e+02 -1.3710e+03  1e+03  2e-02  9e-15\n",
      " 3: -4.4119e+02 -7.5464e+02  3e+02  5e-03  8e-15\n",
      " 4: -4.7842e+02 -5.8509e+02  1e+02  5e-04  8e-15\n",
      " 5: -4.9392e+02 -5.2894e+02  4e+01  1e-04  8e-15\n",
      " 6: -4.9931e+02 -5.1319e+02  1e+01  3e-05  8e-15\n",
      " 7: -5.0143e+02 -5.0716e+02  6e+00  2e-13  9e-15\n",
      " 8: -5.0278e+02 -5.0408e+02  1e+00  8e-13  8e-15\n",
      " 9: -5.0315e+02 -5.0328e+02  1e-01  8e-13  9e-15\n",
      "10: -5.0319e+02 -5.0320e+02  4e-03  6e-13  9e-15\n",
      "11: -5.0319e+02 -5.0319e+02  7e-05  7e-13  9e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.2836e+01 -7.1347e+03  3e+04  2e+00  5e-15\n",
      " 1: -4.5561e+01 -3.4670e+03  6e+03  2e-01  2e-15\n",
      " 2: -6.5966e+00 -7.3664e+02  1e+03  3e-02  6e-15\n",
      " 3: -2.9623e+01 -1.6707e+02  2e+02  4e-03  3e-15\n",
      " 4: -4.5780e+01 -8.6304e+01  4e+01  9e-04  2e-15\n",
      " 5: -5.2466e+01 -6.7231e+01  2e+01  2e-04  2e-15\n",
      " 6: -5.5594e+01 -6.0481e+01  5e+00  4e-05  2e-15\n",
      " 7: -5.6733e+01 -5.8387e+01  2e+00  6e-06  2e-15\n",
      " 8: -5.7241e+01 -5.7533e+01  3e-01  3e-07  2e-15\n",
      " 9: -5.7346e+01 -5.7382e+01  4e-02  4e-08  2e-15\n",
      "10: -5.7361e+01 -5.7362e+01  7e-04  3e-10  2e-15\n",
      "11: -5.7361e+01 -5.7361e+01  2e-05  6e-12  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2223e+02 -8.4141e+03  4e+04  2e+00  5e-15\n",
      " 1: -1.3588e+02 -4.6583e+03  8e+03  3e-01  3e-15\n",
      " 2: -8.2884e+01 -1.3246e+03  2e+03  5e-02  4e-15\n",
      " 3: -1.3866e+02 -4.3341e+02  3e+02  8e-03  3e-15\n",
      " 4: -1.6992e+02 -2.3917e+02  7e+01  1e-03  2e-15\n",
      " 5: -1.8157e+02 -2.0218e+02  2e+01  2e-04  2e-15\n",
      " 6: -1.8572e+02 -1.9211e+02  6e+00  5e-05  2e-15\n",
      " 7: -1.8735e+02 -1.8861e+02  1e+00  4e-06  2e-15\n",
      " 8: -1.8774e+02 -1.8789e+02  1e-01  3e-07  2e-15\n",
      " 9: -1.8779e+02 -1.8780e+02  5e-03  8e-09  2e-15\n",
      "10: -1.8779e+02 -1.8779e+02  1e-04  1e-10  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1714e+02 -7.2200e+03  3e+04  2e+00  5e-15\n",
      " 1: -5.7504e+01 -3.5569e+03  6e+03  2e-01  2e-15\n",
      " 2: -2.3175e+01 -6.8503e+02  8e+02  2e-02  4e-15\n",
      " 3: -6.5374e+01 -1.7868e+02  1e+02  3e-03  3e-15\n",
      " 4: -8.2099e+01 -1.1645e+02  4e+01  6e-04  2e-15\n",
      " 5: -8.8468e+01 -1.0144e+02  1e+01  1e-04  2e-15\n",
      " 6: -9.1379e+01 -9.5512e+01  4e+00  1e-05  1e-15\n",
      " 7: -9.2466e+01 -9.3422e+01  1e+00  1e-06  2e-15\n",
      " 8: -9.2761e+01 -9.2921e+01  2e-01  9e-08  1e-15\n",
      " 9: -9.2821e+01 -9.2827e+01  6e-03  2e-09  2e-15\n",
      "10: -9.2823e+01 -9.2823e+01  1e-04  4e-11  2e-15\n",
      "11: -9.2823e+01 -9.2823e+01  3e-06  7e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5598e+02 -6.9922e+03  3e+04  2e+00  5e-15\n",
      " 1: -8.8655e+01 -3.4859e+03  6e+03  2e-01  2e-15\n",
      " 2: -5.9434e+01 -7.3616e+02  8e+02  2e-02  4e-15\n",
      " 3: -1.0521e+02 -2.6175e+02  2e+02  4e-03  3e-15\n",
      " 4: -1.2171e+02 -1.8069e+02  6e+01  1e-03  2e-15\n",
      " 5: -1.2850e+02 -1.5675e+02  3e+01  3e-14  2e-15\n",
      " 6: -1.3314e+02 -1.4202e+02  9e+00  2e-13  2e-15\n",
      " 7: -1.3446e+02 -1.3848e+02  4e+00  1e-13  2e-15\n",
      " 8: -1.3539e+02 -1.3650e+02  1e+00  9e-14  2e-15\n",
      " 9: -1.3573e+02 -1.3581e+02  8e-02  2e-13  2e-15\n",
      "10: -1.3576e+02 -1.3576e+02  2e-03  3e-13  2e-15\n",
      "11: -1.3576e+02 -1.3576e+02  6e-05  2e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.9772e+02 -9.6565e+03  4e+04  2e+00  1e-14\n",
      " 1: -7.1427e+02 -5.9961e+03  8e+03  2e-01  2e-14\n",
      " 2: -7.5707e+02 -1.7361e+03  1e+03  3e-02  2e-14\n",
      " 3: -8.6971e+02 -1.1390e+03  3e+02  5e-03  2e-14\n",
      " 4: -9.1628e+02 -1.0034e+03  9e+01  7e-04  2e-14\n",
      " 5: -9.3428e+02 -9.5281e+02  2e+01  8e-05  2e-14\n",
      " 6: -9.3898e+02 -9.4171e+02  3e+00  8e-06  2e-14\n",
      " 7: -9.3981e+02 -9.3998e+02  2e-01  4e-07  2e-14\n",
      " 8: -9.3987e+02 -9.3987e+02  7e-03  1e-08  2e-14\n",
      " 9: -9.3987e+02 -9.3987e+02  2e-04  2e-10  2e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.3076e+01 -7.2188e+03  3e+04  2e+00  5e-15\n",
      " 1: -4.4606e+01 -3.5557e+03  6e+03  2e-01  2e-15\n",
      " 2: -6.2621e+00 -7.8910e+02  1e+03  4e-02  8e-15\n",
      " 3: -3.2395e+01 -1.7430e+02  2e+02  4e-03  3e-15\n",
      " 4: -4.9879e+01 -9.0250e+01  4e+01  8e-04  2e-15\n",
      " 5: -5.7061e+01 -7.1118e+01  1e+01  1e-04  2e-15\n",
      " 6: -6.0160e+01 -6.4483e+01  4e+00  1e-05  2e-15\n",
      " 7: -6.1222e+01 -6.2514e+01  1e+00  3e-06  2e-15\n",
      " 8: -6.1633e+01 -6.1812e+01  2e-01  4e-14  2e-15\n",
      " 9: -6.1706e+01 -6.1711e+01  5e-03  2e-14  2e-15\n",
      "10: -6.1709e+01 -6.1709e+01  9e-05  6e-14  2e-15\n",
      "11: -6.1709e+01 -6.1709e+01  2e-06  3e-14  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2465e+02 -6.8855e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.4528e+02 -3.4652e+03  5e+03  2e-01  2e-15\n",
      " 2: -1.2473e+02 -7.6671e+02  8e+02  2e-02  3e-15\n",
      " 3: -1.7986e+02 -3.1703e+02  1e+02  3e-03  3e-15\n",
      " 4: -1.9975e+02 -2.3811e+02  4e+01  6e-04  2e-15\n",
      " 5: -2.0764e+02 -2.1714e+02  1e+01  9e-05  2e-15\n",
      " 6: -2.1013e+02 -2.1205e+02  2e+00  1e-05  2e-15\n",
      " 7: -2.1073e+02 -2.1097e+02  2e-01  7e-07  2e-15\n",
      " 8: -2.1081e+02 -2.1082e+02  1e-02  3e-08  2e-15\n",
      " 9: -2.1082e+02 -2.1082e+02  3e-04  6e-10  2e-15\n",
      "10: -2.1082e+02 -2.1082e+02  6e-06  7e-12  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1407e+02 -6.5885e+03  3e+04  2e+00  4e-15\n",
      " 1: -5.4731e+01 -3.0743e+03  5e+03  2e-01  2e-15\n",
      " 2: -3.3614e+01 -5.3901e+02  6e+02  2e-02  5e-15\n",
      " 3: -7.3851e+01 -1.8900e+02  1e+02  3e-03  3e-15\n",
      " 4: -8.8826e+01 -1.2601e+02  4e+01  7e-04  2e-15\n",
      " 5: -9.4967e+01 -1.0838e+02  1e+01  2e-04  2e-15\n",
      " 6: -9.7972e+01 -1.0158e+02  4e+00  2e-05  1e-15\n",
      " 7: -9.8948e+01 -9.9746e+01  8e-01  2e-06  1e-15\n",
      " 8: -9.9202e+01 -9.9319e+01  1e-01  2e-07  1e-15\n",
      " 9: -9.9246e+01 -9.9249e+01  3e-03  3e-09  2e-15\n",
      "10: -9.9248e+01 -9.9248e+01  7e-05  7e-11  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0532e+02 -7.5501e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.2812e+02 -3.9858e+03  6e+03  2e-01  3e-15\n",
      " 2: -9.5965e+01 -7.8642e+02  8e+02  2e-02  6e-15\n",
      " 3: -1.4760e+02 -3.3416e+02  2e+02  5e-03  3e-15\n",
      " 4: -1.6699e+02 -2.3319e+02  7e+01  1e-03  2e-15\n",
      " 5: -1.7567e+02 -2.0025e+02  2e+01  2e-04  2e-15\n",
      " 6: -1.7996e+02 -1.8769e+02  8e+00  3e-05  2e-15\n",
      " 7: -1.8147e+02 -1.8390e+02  2e+00  9e-14  2e-15\n",
      " 8: -1.8213e+02 -1.8255e+02  4e-01  7e-14  2e-15\n",
      " 9: -1.8227e+02 -1.8229e+02  2e-02  3e-13  2e-15\n",
      "10: -1.8227e+02 -1.8227e+02  4e-04  7e-14  2e-15\n",
      "11: -1.8227e+02 -1.8227e+02  6e-06  2e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7910e+02 -8.4558e+03  4e+04  2e+00  1e-14\n",
      " 1: -2.7287e+02 -4.7988e+03  8e+03  3e-01  1e-14\n",
      " 2: -2.3220e+02 -1.1232e+03  1e+03  2e-02  1e-14\n",
      " 3: -3.0159e+02 -5.9115e+02  3e+02  6e-03  1e-14\n",
      " 4: -3.3487e+02 -4.4664e+02  1e+02  1e-03  1e-14\n",
      " 5: -3.5167e+02 -3.9012e+02  4e+01  3e-04  1e-14\n",
      " 6: -3.5933e+02 -3.6849e+02  9e+00  2e-05  1e-14\n",
      " 7: -3.6174e+02 -3.6303e+02  1e+00  6e-07  1e-14\n",
      " 8: -3.6215e+02 -3.6228e+02  1e-01  5e-08  1e-14\n",
      " 9: -3.6219e+02 -3.6220e+02  5e-03  1e-09  1e-14\n",
      "10: -3.6219e+02 -3.6219e+02  9e-05  2e-11  1e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.5875e+02 -7.3163e+03  3e+04  2e+00  5e-15\n",
      " 1: -1.6843e+02 -3.8409e+03  5e+03  2e-01  3e-15\n",
      " 2: -1.7501e+02 -7.0581e+02  6e+02  1e-02  5e-15\n",
      " 3: -2.3096e+02 -3.8531e+02  2e+02  3e-03  3e-15\n",
      " 4: -2.5074e+02 -3.0060e+02  5e+01  6e-04  2e-15\n",
      " 5: -2.5761e+02 -2.7802e+02  2e+01  2e-04  2e-15\n",
      " 6: -2.6135e+02 -2.6687e+02  6e+00  1e-05  2e-15\n",
      " 7: -2.6251e+02 -2.6379e+02  1e+00  2e-13  2e-15\n",
      " 8: -2.6285e+02 -2.6298e+02  1e-01  3e-13  2e-15\n",
      " 9: -2.6289e+02 -2.6289e+02  5e-03  3e-13  2e-15\n",
      "10: -2.6289e+02 -2.6289e+02  1e-04  1e-14  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7302e+02 -7.5634e+03  3e+04  2e+00  6e-15\n",
      " 1: -1.9617e+02 -4.0276e+03  6e+03  2e-01  4e-15\n",
      " 2: -1.7676e+02 -7.9836e+02  7e+02  2e-02  6e-15\n",
      " 3: -2.2909e+02 -4.2786e+02  2e+02  4e-03  4e-15\n",
      " 4: -2.5164e+02 -3.1446e+02  6e+01  7e-04  3e-15\n",
      " 5: -2.6164e+02 -2.8081e+02  2e+01  2e-05  3e-15\n",
      " 6: -2.6538e+02 -2.6993e+02  5e+00  7e-07  3e-15\n",
      " 7: -2.6630e+02 -2.6772e+02  1e+00  5e-13  4e-15\n",
      " 8: -2.6665e+02 -2.6698e+02  3e-01  1e-13  3e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9: -2.6674e+02 -2.6679e+02  5e-02  2e-13  3e-15\n",
      "10: -2.6676e+02 -2.6676e+02  1e-03  3e-13  3e-15\n",
      "11: -2.6676e+02 -2.6676e+02  1e-05  4e-14  4e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1028e+02 -7.5103e+03  4e+04  2e+00  5e-15\n",
      " 1: -5.6897e+01 -3.8143e+03  7e+03  3e-01  3e-15\n",
      " 2: -1.3830e+01 -9.2363e+02  1e+03  4e-02  7e-15\n",
      " 3: -3.9528e+01 -1.9616e+02  2e+02  4e-03  4e-15\n",
      " 4: -5.5680e+01 -1.2195e+02  7e+01  2e-03  2e-15\n",
      " 5: -6.4887e+01 -8.8241e+01  2e+01  1e-04  2e-15\n",
      " 6: -6.9418e+01 -7.6829e+01  7e+00  2e-05  2e-15\n",
      " 7: -7.1201e+01 -7.3118e+01  2e+00  2e-06  2e-15\n",
      " 8: -7.1797e+01 -7.2062e+01  3e-01  1e-07  2e-15\n",
      " 9: -7.1900e+01 -7.1908e+01  8e-03  2e-09  2e-15\n",
      "10: -7.1903e+01 -7.1903e+01  1e-04  3e-11  2e-15\n",
      "11: -7.1903e+01 -7.1903e+01  2e-06  3e-13  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3801e+02 -8.0319e+03  4e+04  2e+00  5e-15\n",
      " 1: -2.4315e+02 -4.4272e+03  7e+03  2e-01  3e-15\n",
      " 2: -2.2086e+02 -9.6970e+02  9e+02  2e-02  5e-15\n",
      " 3: -2.8364e+02 -5.1393e+02  2e+02  5e-03  3e-15\n",
      " 4: -3.1190e+02 -3.6929e+02  6e+01  3e-04  3e-15\n",
      " 5: -3.2242e+02 -3.3848e+02  2e+01  4e-05  2e-15\n",
      " 6: -3.2587e+02 -3.2978e+02  4e+00  6e-06  2e-15\n",
      " 7: -3.2693e+02 -3.2738e+02  4e-01  4e-07  2e-15\n",
      " 8: -3.2708e+02 -3.2710e+02  2e-02  1e-08  3e-15\n",
      " 9: -3.2708e+02 -3.2709e+02  5e-04  2e-10  3e-15\n",
      "10: -3.2708e+02 -3.2708e+02  1e-05  3e-12  3e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3972e+02 -6.9017e+03  3e+04  2e+00  5e-15\n",
      " 1: -7.4093e+01 -3.3717e+03  5e+03  2e-01  2e-15\n",
      " 2: -4.9322e+01 -5.8506e+02  6e+02  2e-02  5e-15\n",
      " 3: -9.5462e+01 -2.0704e+02  1e+02  3e-03  3e-15\n",
      " 4: -1.1120e+02 -1.4547e+02  4e+01  6e-04  2e-15\n",
      " 5: -1.1785e+02 -1.2868e+02  1e+01  6e-05  2e-15\n",
      " 6: -1.2042e+02 -1.2319e+02  3e+00  8e-06  2e-15\n",
      " 7: -1.2125e+02 -1.2164e+02  4e-01  4e-07  2e-15\n",
      " 8: -1.2138e+02 -1.2141e+02  2e-02  7e-09  2e-15\n",
      " 9: -1.2139e+02 -1.2139e+02  7e-04  2e-10  2e-15\n",
      "10: -1.2139e+02 -1.2139e+02  1e-05  3e-12  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4021e+02 -7.5807e+03  4e+04  2e+00  5e-15\n",
      " 1: -7.7474e+01 -3.9413e+03  7e+03  3e-01  3e-15\n",
      " 2: -3.7302e+01 -1.0367e+03  1e+03  4e-02  4e-15\n",
      " 3: -7.4177e+01 -2.7628e+02  2e+02  6e-03  4e-15\n",
      " 4: -9.3886e+01 -1.5833e+02  7e+01  1e-03  3e-15\n",
      " 5: -1.0307e+02 -1.2356e+02  2e+01  3e-04  2e-15\n",
      " 6: -1.0675e+02 -1.1333e+02  7e+00  5e-05  2e-15\n",
      " 7: -1.0821e+02 -1.0986e+02  2e+00  6e-06  2e-15\n",
      " 8: -1.0865e+02 -1.0897e+02  3e-01  7e-07  2e-15\n",
      " 9: -1.0875e+02 -1.0879e+02  4e-02  6e-08  2e-15\n",
      "10: -1.0876e+02 -1.0876e+02  1e-03  1e-09  2e-15\n",
      "11: -1.0876e+02 -1.0876e+02  2e-05  2e-11  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8746e+02 -9.5957e+03  5e+04  3e+00  8e-15\n",
      " 1: -2.8432e+02 -5.5742e+03  9e+03  3e-01  9e-15\n",
      " 2: -2.5152e+02 -1.4261e+03  1e+03  3e-02  9e-15\n",
      " 3: -3.0818e+02 -7.0514e+02  4e+02  9e-03  8e-15\n",
      " 4: -3.4189e+02 -4.9364e+02  2e+02  2e-03  8e-15\n",
      " 5: -3.5935e+02 -4.1679e+02  6e+01  4e-04  9e-15\n",
      " 6: -3.6813e+02 -3.8647e+02  2e+01  2e-13  9e-15\n",
      " 7: -3.7153e+02 -3.7782e+02  6e+00  6e-14  9e-15\n",
      " 8: -3.7293e+02 -3.7451e+02  2e+00  3e-13  1e-14\n",
      " 9: -3.7345e+02 -3.7358e+02  1e-01  5e-13  1e-14\n",
      "10: -3.7350e+02 -3.7350e+02  4e-03  4e-13  1e-14\n",
      "11: -3.7350e+02 -3.7350e+02  8e-05  3e-13  1e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5990e+02 -7.2285e+03  3e+04  2e+00  5e-15\n",
      " 1: -7.8001e+01 -3.7404e+03  6e+03  2e-01  2e-15\n",
      " 2: -5.8062e+01 -7.5437e+02  8e+02  2e-02  6e-15\n",
      " 3: -1.2171e+02 -2.6113e+02  1e+02  3e-03  3e-15\n",
      " 4: -1.4164e+02 -1.8153e+02  4e+01  6e-04  2e-15\n",
      " 5: -1.4951e+02 -1.6040e+02  1e+01  6e-05  2e-15\n",
      " 6: -1.5210e+02 -1.5479e+02  3e+00  8e-06  2e-15\n",
      " 7: -1.5284e+02 -1.5330e+02  5e-01  9e-07  2e-15\n",
      " 8: -1.5299e+02 -1.5303e+02  4e-02  5e-08  2e-15\n",
      " 9: -1.5300e+02 -1.5301e+02  7e-04  8e-10  2e-15\n",
      "10: -1.5300e+02 -1.5300e+02  1e-05  1e-11  2e-15\n",
      "Optimal solution found.\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "7 8\n",
      "7 9\n",
      "8 9\n",
      "Training time (test): 2238.696s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "def train(X, Y):\n",
    "    alpha_dict = get_alpha_s(X, Y)\n",
    "    return get_b_dict(X, Y, alpha_dict), alpha_dict\n",
    "\n",
    "b_dict, alpha_dict = train(X_train, Y_train)\n",
    "print(f\"Training time (test): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving learnt dictionaries\n",
    "np.save('alpha.npy', alpha_dict)\n",
    "np.save('b_dict.npy', b_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    e = 1 + np.exp(-x)\n",
    "    return 1 / e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on validation data\n",
    "def get_prediction_dict(alpha_d, b_d, X, Y, x_t):\n",
    "    \n",
    "    m = x_t.shape[-1]\n",
    "    score_array = np.zeros((10, m))\n",
    "    votes = np.zeros((10, m))\n",
    "    index = [i for i in range(10)]\n",
    "    index = np.repeat(index, m).reshape((10, m))\n",
    "    prediction = np.array([])\n",
    "    \n",
    "    # Forming the score array    \n",
    "    for i in range(10):\n",
    "        for j in range(i + 1, 10):\n",
    "            print(i, j)\n",
    "            x = np.vstack((X[i].T, X[j].T)).T\n",
    "            y = np.append(Y[i], Y[j])\n",
    "            y[y == i] = -1\n",
    "            y[y == j % 10] = 1\n",
    "            score = get_gauss_prediction(alpha_d[i, j], b_d[i, j], x, y, x_t)\n",
    "            \n",
    "            # Tiebreaker      \n",
    "            score_i = np.array(score)\n",
    "            score_i[score_i >= 0] = 0\n",
    "            score_i = np.abs(score_i)\n",
    "            \n",
    "            # Tiebreaker      \n",
    "            score_j = np.array(score)\n",
    "            score_j[score_j < 0] = 0\n",
    "            score_j = np.abs(score_j)\n",
    "\n",
    "            pred_i = np.array(score)\n",
    "            pred_i[pred_i >= 0] = 0\n",
    "            pred_i[pred_i < 0] = 1\n",
    "            \n",
    "            pred_j = np.array(score)\n",
    "            pred_j[pred_j >= 0] = 1\n",
    "            pred_j[pred_j < 0] = 0\n",
    "            \n",
    "            votes[i] += pred_i    \n",
    "            votes[j] += pred_j\n",
    "            score_array[i] += score_i\n",
    "            score_array[j] += score_j\n",
    "            \n",
    "    all_arrays = np.dstack((votes.T, score_array.T, index.T))\n",
    "    for i in range(m):\n",
    "        prediction = np.append(prediction, max(tuple(map(tuple, all_arrays[i])))[2])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "7 8\n",
      "7 9\n",
      "8 9\n",
      "Prediction time (test): 798.657s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "prediction_test = get_prediction_dict(alpha_dict, b_dict, X_train, Y_train, x_test_m)\n",
    "print(f\"Prediction time (test): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is(test): 85.07701540308062\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(y_pred, y_actual):\n",
    "    total = y_actual.shape[0]\n",
    "    count = 0\n",
    "    for (i, p) in enumerate(y_pred):\n",
    "        if p == y_actual[i]:\n",
    "            count += 1\n",
    "    return count * 100 / total\n",
    "\n",
    "print(\"Test accuracy is(test):\", get_accuracy(prediction_test, y_test_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "7 8\n",
      "7 9\n",
      "8 9\n",
      "Prediction time (validation): 370.653s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "prediction_val = get_prediction_dict(alpha_dict, b_dict, X_train, Y_train, x_validation)\n",
    "print(f\"Prediction time (validation): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is(validation): 84.9139655862345\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy is(validation):\", get_accuracy(prediction_val, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 193.81046891212463\n"
     ]
    }
   ],
   "source": [
    "svm_model_gaussian = SVC(kernel='rbf', gamma=gamma, C=C)\n",
    "\n",
    "t0 = time()\n",
    "svm_model_gaussian.fit(x_train_m.T, y_train_m)\n",
    "print(\"Training time\", time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time(test) 47.07362985610962\n",
      "Gaussian Accuracy(test): 0.8807761552310462\n",
      "Prediction time(validation) 23.739629983901978\n",
      "Gaussian Accuracy(validation): 0.8791516606642658\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "svm_predictions = svm_model_gaussian.predict(x_test_m.T) \n",
    "print(\"Prediction time(test)\", time() - t0)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Gaussian Accuracy(test):\", metrics.accuracy_score(y_test_m, svm_predictions))\n",
    "\n",
    "t0 = time()\n",
    "svm_predictions = svm_model_gaussian.predict(x_validation.T) \n",
    "print(\"Prediction time(validation)\", time() - t0)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Gaussian Accuracy(validation):\", metrics.accuracy_score(y_validation, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sklearn = confusion_matrix(y_validation, svm_predictions) \n",
    "cm_own_implementation = confusion_matrix(y_validation, prediction_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_own_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 1, 2, 3],\n",
    "           [4, 5, 6, 6]])\n",
    "b = np.array([[7, 1, 2, 3],\n",
    "           [4, 5, 6, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.dstack((a, b, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 7, 7), (1, 1, 1), (2, 2, 2), (3, 3, 3))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tuple(map(tuple, c[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "c_vals = [1e-5, 1e-3, 1, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "Gaussian Accuracy(cross - validation) for C = 1 : 0.8371691691691691\n"
     ]
    }
   ],
   "source": [
    "def get_k_fold_accuracy(k, x, y, x_test, y_test, c_list):\n",
    "    kf = KFold(n_splits = k) \n",
    "    \n",
    "    test_accuracy = []\n",
    "    cv_accuracy = []\n",
    "    \n",
    "    for c in c_list:\n",
    "        accuracy = 0\n",
    "        svm_model_gaussian = SVC(kernel='rbf', gamma=gamma, C=c)\n",
    "        \n",
    "        # Predicting on test data      \n",
    "        svm_model_gaussian.fit(x, y)\n",
    "        svm_predictions = svm_model_gaussian.predict(x_test)\n",
    "        acc = metrics.accuracy_score(y_test, svm_predictions)\n",
    "        test_accuracy.append(acc)\n",
    "        \n",
    "        \n",
    "        for train_index, test_index in kf.split(x):\n",
    "            print(\"hi\")\n",
    "            X_tr, X_te = x[train_index], x[test_index]\n",
    "            y_tr, y_te = y[train_index], y[test_index]\n",
    "\n",
    "            # Predicting\n",
    "            svm_model_gaussian.fit(X_tr, y_tr)\n",
    "            svm_predictions = svm_model_gaussian.predict(X_te)\n",
    "\n",
    "            acc = metrics.accuracy_score(y_te, svm_predictions)\n",
    "            accuracy += acc\n",
    "            \n",
    "            # Accuracy  \n",
    "        print(\"Gaussian Accuracy(cross - validation) for C = {} : {}\".format(c, accuracy / k))\n",
    "        cv_accuracy.append(accuracy / k)\n",
    "    return cv_accuracy, test_accuracy\n",
    "\n",
    "cv_accuracy, test_accuracy = get_k_fold_accuracy(5, x_train_m.T, y_train_m, x_test_m.T, y_test_m, c_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8371691691691691]\n",
      "[0.8455382152861144]\n"
     ]
    }
   ],
   "source": [
    "print(cv_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the graph\n",
    "c_vals_log = [np.log(c) for c in c_vals]\n",
    "plt.scatter(c_vals_log, cv_accuracy)\n",
    "plt.plot(c_vals_log, cv_accuracy)\n",
    "plt.plot(c_vals_log, test_accuracy)\n",
    "plt.title(\"Cross validation and test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Log(c)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
