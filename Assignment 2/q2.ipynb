{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "import time\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "from cvxopt import solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the SVM data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "svm_train_data = pandas.read_csv('./data/fashion_mnist/train.csv').values\n",
    "svm_test_data = pandas.read_csv('./data/fashion_mnist/test.csv').values\n",
    "svm_validation_data = pandas.read_csv('./data/fashion_mnist/val.csv').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required data\n",
    "svm_train_data_r = svm_train_data[(svm_train_data[:, -1] == (d + 1) % 10) + (svm_train_data[:, -1] == d), :]\n",
    "svm_test_data_r = svm_test_data[(svm_test_data[:, -1] == (d + 1) % 10) + (svm_test_data[:, -1] == d), :]\n",
    "svm_validation_data_r = svm_validation_data[(svm_validation_data[:, -1] == (d + 1) % 10) + (svm_validation_data[:, -1] == d), :]\n",
    "svm_train_data_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading y's\n",
    "y_train = svm_train_data_r[:, -1]\n",
    "y_train[y_train == d] = -1\n",
    "y_train[y_train == (d + 1) % 10] = 1\n",
    "\n",
    "y_test = svm_test_data_r[:, -1]\n",
    "y_test[y_test == d] = -1\n",
    "y_test[y_test == (d + 1) % 10] = 1\n",
    "\n",
    "y_val = svm_validation_data_r[:, -1]\n",
    "y_val[y_val == d] = -1\n",
    "y_val[y_val == (d + 1) % 10] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading x's and normalising\n",
    "x_train = (np.delete(svm_train_data_r, -1, axis = 1) / 255).T\n",
    "x_test = (np.delete(svm_test_data_r, -1, axis = 1) / 255).T\n",
    "x_val = (np.delete(svm_validation_data_r, -1, axis = 1) / 255).T\n",
    "\n",
    "# Noise\n",
    "C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating P matrix\n",
    "y_diag = y_train.reshape((-1, 1))\n",
    "p_matrix = np.matmul(x_train.T, x_train)\n",
    "p_matrix = y_diag * p_matrix\n",
    "y_diag = y_diag.T\n",
    "p_matrix = p_matrix * y_diag\n",
    "p_matrix = matrix(p_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating q matrix\n",
    "q_matrix = -matrix(np.ones_like(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating A and b matrices\n",
    "A_matrix = matrix(y_diag) \n",
    "b_matrix = matrix([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating G and h matrices\n",
    "G_1 = np.identity(np.shape(y_train)[0])\n",
    "h_1 = C * np.ones_like(y_train)\n",
    "G_2 = -G_1\n",
    "h_2 = 0 * h_1\n",
    "\n",
    "G_matrix = matrix(np.vstack((G_1, G_2)))\n",
    "h_matrix = matrix(np.append(h_1, h_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.2396e+02 -9.3983e+03  5e+04  3e+00  3e-12\n",
      " 1: -3.3568e+02 -5.4793e+03  1e+04  5e-01  3e-12\n",
      " 2: -2.0714e+02 -1.8273e+03  3e+03  1e-01  2e-12\n",
      " 3: -1.4999e+02 -9.1602e+02  1e+03  5e-02  1e-12\n",
      " 4: -1.1131e+02 -4.9405e+02  6e+02  2e-02  1e-12\n",
      " 5: -9.0544e+01 -3.1115e+02  3e+02  8e-03  9e-13\n",
      " 6: -8.5666e+01 -1.4689e+02  7e+01  6e-04  1e-12\n",
      " 7: -9.2854e+01 -1.1845e+02  3e+01  2e-14  1e-12\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Solving the problem\n",
    "sol = solvers.qp(p_matrix, q_matrix, G_matrix, h_matrix, A_matrix, b_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating alpha\n",
    "alpha = np.array(sol['x'])\n",
    "print(\"Number of support vectors are:\", np.where(alpha > 1e-5)[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating W\n",
    "y_diag = (y_train.reshape((-1, 1))).T\n",
    "w = (x_train * y_diag) @ alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating b\n",
    "x_temp_0 = svm_train_data[(svm_train_data[:, -1] == d), :]\n",
    "x_temp_0 = (np.delete(x_temp_0, -1, axis = 1) / 255).T\n",
    "x_temp_1 = svm_train_data[(svm_train_data[:, -1] == (d + 1) % 10), :]\n",
    "x_temp_1 = (np.delete(x_temp_1, -1, axis = 1) / 255).T\n",
    "x_temp_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = np.max(w.T @ x_temp_0)\n",
    "minimum = np.min(w.T @ x_temp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = - (maximum + minimum) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on test data\n",
    "pred_test = (w.T @ x_test) + b\n",
    "pred_test[pred_test >= 0] = 1\n",
    "pred_test[pred_test < 0] = -1\n",
    "count = 0\n",
    "total = pred_test.shape[1]\n",
    "for (i, p) in enumerate(pred_test[0, :]):\n",
    "    if p == y_test[i]:\n",
    "        count += 1\n",
    "print(\"Accuracy is {}\".format(count * 100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on validation data\n",
    "pred_val = (w.T @ x_val) + b\n",
    "pred_val[pred_val >= 0] = 1\n",
    "pred_val[pred_val < 0] = -1\n",
    "count = 0\n",
    "total = pred_val.shape[1]\n",
    "for (i, p) in enumerate(pred_val[0, :]):\n",
    "    if p == y_val[i]:\n",
    "        count += 1\n",
    "print(\"Accuracy is {}\".format(count * 100 / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, cdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Gaussian\n",
    "gamma = 0.05\n",
    "m = y_train.shape[0]\n",
    "pairwise_dists = squareform(pdist(x_train.T, 'euclidean'))\n",
    "k_matrix = np.exp(- gamma * pairwise_dists ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing P_matrix\n",
    "y_diag = y_train.reshape((-1, 1))\n",
    "p_matrix = k_matrix\n",
    "p_matrix = y_diag * p_matrix\n",
    "y_diag = y_diag.T\n",
    "p_matrix = p_matrix * y_diag\n",
    "p_matrix = matrix(p_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving the problem\n",
    "sol = solvers.qp(p_matrix, q_matrix, G_matrix, h_matrix, A_matrix, b_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating alpha\n",
    "alpha = np.array(sol['x'])\n",
    "print(\"Number of support vectors are: \", np.where(alpha > 1e-5)[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning wTx\n",
    "# pairwise_dists_2 = (cdist(x_train.T, x_test.T))\n",
    "# k_matrix_test = np.exp(- gamma * pairwise_dists_2 ** 2)\n",
    "# def get_w_t_x(x_j):\n",
    "#     x_temp = np.exp(-gamma * np.linalg.norm(x_train - x_j[:, None], axis = 0) ** 2)\n",
    "#     return np.sum(alpha[:, 0] * y_train * x_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating B\n",
    "x_temp_0 = svm_train_data[(svm_train_data[:, -1] == d), :]\n",
    "x_temp_0 = (np.delete(x_temp_0, -1, axis = 1) / 255).T\n",
    "x_temp_1 = svm_train_data[(svm_train_data[:, -1] == (d + 1) % 10), :]\n",
    "x_temp_1 = (np.delete(x_temp_1, -1, axis = 1) / 255).T\n",
    "x_temp_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list_0 = np.sum(y_train[:, None] * alpha * np.exp(-gamma * cdist(x_train.T, x_temp_0.T) ** 2), axis = 0)\n",
    "x_list_1 = np.sum(y_train[:, None] * alpha * np.exp(-gamma * cdist(x_train.T, x_temp_1.T) ** 2), axis = 0)\n",
    "# print(x_list_0.shape)\n",
    "# x_list_0 = np.apply_along_axis(get_w_t_x, 0, x_temp_0)\n",
    "# x_list_1 = np.apply_along_axis(get_w_t_x, 0, x_temp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = -(np.max(x_list_0) + np.min(x_list_1)) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on test data\n",
    "t0 = time()\n",
    "pairwise_dists_2 = (cdist(x_train.T, x_test.T))\n",
    "k_matrix_test = y_train[:, None] * alpha * np.exp(- gamma * pairwise_dists_2 ** 2)\n",
    "pred_test = np.sum(k_matrix_test, axis = 0) + b\n",
    "pred_test[pred_test >= 0] = 1\n",
    "pred_test[pred_test < 0] = -1\n",
    "count = 0\n",
    "total = pred_test.shape[0]\n",
    "for (i, p) in enumerate(pred_test):\n",
    "    if p == y_test[i]:\n",
    "        count += 1\n",
    "print(\"Accuracy is {}\".format(count * 100 / total))\n",
    "print(f\"Prediction time (test): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on validation data\n",
    "t0 = time()\n",
    "pairwise_dists_2 = (cdist(x_train.T, x_val.T))\n",
    "k_matrix_val = y_train[:, None] * alpha * np.exp(- gamma * pairwise_dists_2 ** 2)\n",
    "pred_val = np.sum(k_matrix_val, axis = 0) + b\n",
    "pred_val[pred_val >= 0] = 1\n",
    "pred_val[pred_val < 0] = -1\n",
    "count = 0\n",
    "total = pred_val.shape[0]\n",
    "for (i, p) in enumerate(pred_val):\n",
    "    if p == y_val[i]:\n",
    "        count += 1\n",
    "print(\"Accuracy is {}\".format(count * 100 / total))\n",
    "print(f\"Prediction time (Validation): {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear \n",
    "# Create a svm Classifier\n",
    "clf = SVC(kernel='linear', C=C) # Linear Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(x_train.T, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Linear Accuracy(test):\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Predict the response for validation dataset\n",
    "y_pred = clf.predict(x_val.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Linear Accuracy(validation):\", metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Number of support vectors:\", np.sum(clf.n_support_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian\n",
    "# Create a svm Classifier\n",
    "clf = SVC(kernel='rbf', gamma=gamma, C=C) # Gaussian Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(x_train.T, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Gaussian Accuracy(test):\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Predict the response for validation dataset\n",
    "y_pred = clf.predict(x_val.T)\n",
    "\n",
    "# Predicting accuracy\n",
    "print(\"Gaussian Accuracy(validation):\", metrics.accuracy_score(y_val, y_pred))\n",
    "print(\"Number of support vectors:\", np.sum(clf.n_support_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading training data\n",
    "X_train = {}\n",
    "Y_train = {}\n",
    "for i in range(10):\n",
    "    svm_train_data_r = svm_train_data[(svm_train_data[:, -1] == i), :]\n",
    "    Y_train[i] = svm_train_data_r[:, -1]\n",
    "    X_train[i] = (np.delete(svm_train_data_r, -1, axis = 1) / 255).T\n",
    "\n",
    "# Reading test data\n",
    "X_test = {}\n",
    "Y_test = {}\n",
    "for i in range(10):\n",
    "    svm_test_data_r = svm_test_data[(svm_test_data[:, -1] == i), :]\n",
    "    Y_test[i] = svm_test_data_r[:, -1]\n",
    "    X_test[i] = (np.delete(svm_test_data_r, -1, axis = 1) / 255).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating P matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
